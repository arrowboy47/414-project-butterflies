---
title: "STAT 414 - Part 2 Update"
author: "Kyle Nessen, Justin Mai, Aiden Kelly, Arneh Begi"
date: "2024-10-28"
format: docx
editor: visual
---

```{r include=FALSE}
library(tidyverse)
library(lme4)
library(performance)
```

## Introduction

Every fall, monarch butterflies migrate from the western United States to coastal California in search of forested areas where they cluster in large numbers. It is hypothesized that the butterflies seek these habitats or groves because they offer a particular microclimate regarding temperature, humidity, and light. Within each grove, butterflies often cluster at the same tree (and even branch), year after year, spurring scientists to hypothesize that these areas are selected for their microclimatic characteristics over other areas within the same grove. Saniee and Villablanca (2022) tested this hypothesis directly by installing weather station 'arrays' at the butterfly clustering sites ('cluster') and four orthogonal positions from the butterflies (NW, NE, SW, SE). They repeated these weather station arrays at eight overwintering groves along an N-S gradient along the California coast.

Our research question investigates whether climatic conditions are significantly different at the cluster site compared to the four controls (NW, NE, SW, SE) and whether they are consistent across groves at cluster sites.

```{r}
df <- suppressMessages(read_csv('allgr_array_KianaRawdat.csv'))
head(df)
```

## Weight observations based on time of season

The monarch overwintering season occurs from the beginning of October through the end of February. Weather can be unpredictable at the beginning and end of the season (fall and spring), and butterflies either arrive at groves or leave to begin breeding; thus, they generally occur in low numbers. The highest counts of butterflies occur around Thanksgiving and Christmas, or approximately in the middle of the season. Scientists are usually most "concerned" about storms during this time.

One idea to account for this is to weigh observations based on how far away they are from the middle of the season. We could derive day of the season (`seasonDay`) from the date column (10/1 = 1, 10/2 = 2), then grand mean center our `seasonDay` variable. If we take the absolute value of `seasonDay`, days near the middle of the season would be small, and days toward the beginning or end would be large. We could weigh by dividing one by `seasonDay`.

We are presenting this idea to see if it is worth pursuing or if it is a route we should take with caution.

## Unequal samples across groves

Since not all groves have the same number of observations throughout the overwintering season, should we restrict our analysis to dates where the groves have data? A benefit is that it may provide a better comparison of conditions across sites, but it could also reduce our sample size and miss important data in grove specific conditions on unmonitored dates.

```{r}

grove_counts <- df %>%
  count(grove)

# Plot the counts as a bar chart
ggplot(grove_counts, aes(x = grove, y = n)) +
  geom_bar(stat = "identity") +
  labs(title = "Number of Rows per Grove Type", x = "Grove Type", y = "Row Count") +
  theme_minimal()

```

## Exploratory plots of response variables

Below are box plots of the response variables we plan to test by grove.

```{r}
#Reponse variables by Grove

# Boxplot for Average Temperature by Grove
ggplot(df, aes(x = grove, y = temp.avg, fill = grove)) +
  geom_boxplot() +
  labs(title = "Boxplot of Average Temperature by Grove",
       x = "Grove", y = "Average Temperature (°C)") +
  theme_minimal()

# Boxplot for Minimum Temperature by Grove
ggplot(df, aes(x = grove, y = temp.min, fill = grove)) +
  geom_boxplot() +
  labs(title = "Boxplot of Minimum Temperature by Grove",
       x = "Grove", y = "Minimum Temperature (°C)") +
  theme_minimal()

# Boxplot for Maximum Temperature by Grove
ggplot(df, aes(x = grove, y = temp.max, fill = grove)) +
  geom_boxplot() +
  labs(title = "Boxplot of Maximum Temperature by Grove",
       x = "Grove", y = "Maximum Temperature (°C)") +
  theme_minimal()

# Boxplot for Average Humidity by Grove
ggplot(df, aes(x = grove, y = hum.avg, fill = grove)) +
  geom_boxplot() +
  labs(title = "Boxplot of Average Humidity by Grove",
       x = "Grove", y = "Average Humidity (%)") +
  theme_minimal()

# Boxplot for Average Light by Grove
ggplot(df, aes(x = grove, y = light.avg, fill = grove)) +
  geom_boxplot() +
  labs(title = "Boxplot of Average Light by Grove",
       x = "Grove", y = "Average Light (Lux)") +
  theme_minimal()

# Boxplot for Light Variability (Std Dev) by Grove
ggplot(df, aes(x = grove, y = light.std, fill = grove)) +
  geom_boxplot() +
  labs(title = "Boxplot of Light Standard Deviation by Grove",
       x = "Grove", y = "Light Standard Deviation") +
  theme_minimal()
```

## Preliminary models

Below are a few preliminary models to test our questions. These likely will change in the final report, but we provide them here to give a sense of how we plan to approach the investigation.

### Arrays as fixed effect

```{r}
model1 <- lmer(temp.avg ~ array + (1 | grove), data = df)
summary(model1, corr = FALSE)
#check_model(model1)
```

### Grove as fixed effect

```{r}
model2 <- lmer(temp.avg ~ grove + (1 | array), data = df)
summary(model2, corr = FALSE)
check_model(model2)
```


## Assumptions and thoughts

- non independence of observations within groves (between arrays)
- vars: temp.avg, temp.min, temp.max, hum.avg, light.avg, light.std, cluster controls
- 
```{r}
df <- df |> 
  mutate(
    # Parse the month and day components
    month = as.integer(substr(month.day, 1, 2)),
    day = as.integer(substr(month.day, 4, 5)),
    
    # Assign year based on month
    year = ifelse(month >= 10, 2022, 2023),
    
    # Create a Date column
    Date = as.Date(paste(year, month, day, sep = "-"), format = "%Y-%m-%d"),
    
    # Calculate seasonDay and seasonWeight
    seasonDay = as.numeric(difftime(Date, as.Date("2022-11-15"), units = "days")),
    seasonWeight = 1 / abs(seasonDay)
  )

colSums(is.na(df)) # lots of cols with missing vals so log like wont worksince lmer will drop nas
```  

```{r}
model <- lmer(temp.avg ~ array + (1 | grove),
              data = df, weights = seasonWeight)

summary(model) # each array is signif at 0.05 level

model1 <- lmer(temp.avg ~ array + light.avg +  (1 | grove), data = df, weights = seasonWeight)

summary(model1) 

AIC(model, model1)

model2 <- lmer(temp.avg ~ array + light.avg + hum.avg + (1 | grove), data = df, weights = seasonWeight)

summary(model2) 
AIC(model1, model2) # BIG drop in AIC, so humidity is import in predicting temp.avg even though it is not signif


model3 <- lmer(temp.avg ~ array + light.avg + hum.avg + temp.min + (1 | grove), data = df, weights = seasonWeight)
AIC(model2, model3) # drop in AIC, so temp.min is not important in predicting temp.avg

model4 <- lmer(temp.avg ~ array + light.avg + hum.avg + temp.min + temp.max + (1 | grove), data = df, weights = seasonWeight)
AIC(model3, model4) # drop in AIC, so temp.max is not important in predicting temp.avg

model4a <- lmer(temp.avg ~ array + hum.avg + temp.min + temp.max + (1 | grove), data = df, weights = seasonWeight)
AIC(model4, model4a) # drop in AIC, not that large compared to the others so might be better for simpilicity
summary(model4)l

model_final <- lmer(temp.avg ~ array + light.avg + (1 | grove), data = df, weights = seasonWeight)
summary(model_final) 
# min and max temp explain a lot but it seems kind of redundant to have both in the model since an avg temp is a combo of the two. especially when looking at anova table it is explaiing A LOT of the variance, potentially masking other prds and hiding the effect of array if it exists

# model2a <- lmer(temp.avg ~ array  + hum.avg + (1 | grove), data = df, weights = seasonWeight)
# AIC(model2, model2a) # drop in AIC, so light.avg is not important in predicting temp.avg
```

The array coefficients are not significant, meaning there's no strong evidence of temperature differences between arrays once other predictors (e.g., humidity, light, min/max temp) are included.
However, this doesn't rule out differences entirely—it might be that other predictors explain most of the variability, leaving little independent variation for arrays to explain.

especially since when we looks at a model of just array, each one is significant, but when we add other predictors, they are not. maybe  looking at how much variance is explained by each predictor would be useful

```{r}
anova(model4a)
anova(model2)
library(car)
vif(model4) # no multicollinearity, so signif of each r likely valid



```

```{r}
plot(resid(model4a) ~ fitted(model4a))
qqnorm(resid(model4a))
qqline(resid(model4a))

VarCorr(model4a)
VarCorr(model_final)

```


